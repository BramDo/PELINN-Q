{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bcb2f7d",
   "metadata": {},
   "source": [
    "# Startup Guide\n",
    "\n",
    "This guide explains how to reproduce the PE-LiNN quantum error mitigation experiments shipped in this repository. It captures the exact environment assumptions, commands, deliverables, and tips for adapting the workflow.\n",
    "\n",
    "## 1. Repository Overview\n",
    "\n",
    "- `src/` – core quantum dataset generation logic (`dataset_generator.py`).\n",
    "- `Experiments/dataset_saving.py` – entry point that builds a demo dataset via `GenerateQuantumDataset`.\n",
    "- `Experiments/scripts/train_pelinn_from_npz.py` – trains the PE-LiNN model from a NumPy dataset.\n",
    "- `Experiments/pelinn/` – model definition (`model.py`) and supporting utilities.\n",
    "- `Experiments/data/` – default location for generated datasets (`demo_dataset.npz`).\n",
    "- `Experiments/artifacts_*/` – folders for training outputs (loss curves, prediction plots, JSON summaries).\n",
    "\n",
    "## 2. Prerequisites\n",
    "\n",
    "- Python 3.10 or newer (the project was validated with 3.10).\n",
    "- Windows PowerShell 5.1 (default terminal) with permissions to run local scripts (`Set-ExecutionPolicy -Scope Process RemoteSigned` if needed).\n",
    "- Optional CUDA-capable GPU; training runs fine on CPU but may take longer.\n",
    "- Virtual environment located at `.venv/` in the repository root.\n",
    "\n",
    "### Python packages\n",
    "\n",
    "Install these once inside the virtual environment:\n",
    "\n",
    "```\n",
    "pip install --upgrade pip\n",
    "pip install qiskit qiskit-aer qiskit-ibm-runtime torch matplotlib numpy pandas scipy tqdm\n",
    "```\n",
    "\n",
    "> The generator relies on `qiskit_aer` for simulation. If IBM Quantum Runtime access is available, configure credentials separately (`qiskit-ibm-runtime` is already included above).\n",
    "\n",
    "## 3. Environment Setup\n",
    "\n",
    "All commands below assume the repository root `QAMP_project_group_14` as the working directory.\n",
    "\n",
    "1. Activate the virtual environment:\n",
    "   ```powershell\n",
    "   .\\.venv\\Scripts\\Activate.ps1\n",
    "   ```\n",
    "2. (Optional) Confirm Python and pip resolve to the environment:\n",
    "   ```powershell\n",
    "   python --version\n",
    "   pip --version\n",
    "   ```\n",
    "\n",
    "Stay in the activated shell for the remaining steps.\n",
    "\n",
    "## 4. Generate the Quantum Dataset\n",
    "\n",
    "The demo workflow first produces a NumPy dataset that captures noisy vs. noiseless observable expectations for variational circuits.\n",
    "\n",
    "1. Move into the `Experiments` directory so relative paths align with the script defaults:\n",
    "   ```powershell\n",
    "   Set-Location Experiments  or cd Experiments\n",
    "   ```\n",
    "2. Run the dataset generator:\n",
    "   ```powershell\n",
    "   python dataset_saving.py\n",
    "   ```\n",
    "\n",
    "### What the script does\n",
    "\n",
    "- Imports `GenerateQuantumDataset` from `pelinn.data.dataset_generator`.\n",
    "- Builds 150 samples of 3-qubit variational circuits with depth 4.\n",
    "- Uses `SparsePauliOp(\"ZIZ\")` as the observable and simulates both noisy (`noise_list` empty by default) and noiseless expectations with 1024 shots.\n",
    "- Persists the dataset to `data/demo_dataset.npz` in NumPy archive format via `QuantumDataset.save_dataset(..., format=\"numpy\")`.\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "- `Experiments/data/demo_dataset.npz` containing:\n",
    "  - `X`: noisy expectation values (`shape = (150, 1)`).\n",
    "  - `Y`: noiseless expectation values (same shape as `X`).\n",
    "  - `metadata`: global dataset metadata (`n_samples`, `n_qubits`, `circuit_type`, `shots`, etc.).\n",
    "- Console log confirming the save path.\n",
    "\n",
    "> To explore alternative circuit families, adjust `circuit_type` and `circuit_params` in `dataset_saving.py` before running the command. Supported types include `random`, `random_clifford`, `qaoa`, and `variational` (see `src/dataset_generator.py`).\n",
    "\n",
    "## 5. Train the PE-LiNN Model\n",
    "\n",
    "With the dataset in place, launch the training script (still within `Experiments/`).\n",
    "\n",
    "```powershell\n",
    "python scripts/train_pelinn_from_npz.py --dataset data/demo_dataset.npz --epochs 50 --batch-size 32 --lr 3e-4 --weight-decay 1e-2 --hid-dim 96 --steps 6 --dt 0.25 --output-dir artifacts_new --val-fraction 0.2 --log-level INFO\n",
    "```\n",
    "\n",
    "### Important arguments\n",
    "\n",
    "- `--dataset`: Path to the `.npz` file created earlier.\n",
    "- `--epochs`: Total training epochs (default 40; example uses 50 as in current runs).\n",
    "- `--batch-size`, `--lr`, `--weight-decay`: Optimisation hyperparameters for AdamW.\n",
    "- `--hid-dim`, `--steps`, `--dt`: Architecture controls for the liquid neural network (`PELiNNQEM`).\n",
    "- `--tanh-head`: Optional flag to clamp predictions via `tanh`; omit for raw outputs.\n",
    "- `--val-fraction`: Fraction of data reserved for validation (set to 0 to disable).\n",
    "- `--no-normalise`: Disable feature normalisation if desired.\n",
    "- `--log-level`: Verbosity (`INFO` recommended for progress tracking).\n",
    "- `--seed`: Ensures reproducibility across dataset splits and PyTorch initialisation.\n",
    "\n",
    "The script auto-detects CUDA; if unavailable it falls back to CPU.\n",
    "\n",
    "### Training deliverables (saved under `--output-dir`)\n",
    "\n",
    "- `loss_curve.png`: Training (and validation) loss trajectory across epochs.\n",
    "- `pred_vs_true.png`: Scatter plot of predicted vs. true validation targets (only when validation data exists).\n",
    "- `training_summary.json`: Structured summary containing model configuration, training hyperparameters, dataset stats, and final metrics (MAE, RMSE).\n",
    "\n",
    "Execution also logs per-epoch metrics in the console. The JSON summary is designed for experiment tracking; integrate it with your logging solution as needed.\n",
    "\n",
    "## 6. Extending the Workflow\n",
    "\n",
    "- **Custom noise models**: Update `noise_config` in `dataset_saving.py` with entries supported by `NoiseModelFactory` (see `src/dataset_generator.py`).\n",
    "- **Alternate observables**: Supply additional `SparsePauliOp` entries to the `observables` list for multi-target datasets.\n",
    "- **Batch experiments**: Duplicate the dataset + training commands with modified arguments and direct each run to a unique `--output-dir`.\n",
    "- **Notebook exploration**: `tutorials/Dataset_generation.ipynb` provides an interactive view of dataset creation if you prefer a Jupyter workflow.\n",
    "\n",
    "## 7. Troubleshooting Checklist\n",
    "\n",
    "- **`ModuleNotFoundError`**: Re-check virtual environment activation and that dependencies are installed inside it.\n",
    "- **`FileNotFoundError: Dataset not found`**: Ensure `--dataset` points to the `.npz` file relative to the current working directory or provide an absolute path.\n",
    "- **`Dataset generation returned 0 samples`**: Investigate the circuit parameters or noise configuration; the generator raises this error to catch invalid setups early.\n",
    "- **GPU memory errors**: Reduce `--batch-size` or run on CPU by setting `CUDA_VISIBLE_DEVICES=` before invoking the training script.\n",
    "\n",
    "## 8. Next Steps\n",
    "\n",
    "- Commit experiment artefacts (`artifacts_*` folders) to your tracking repository if needed.\n",
    "- Compare runs by diffing `training_summary.json` files.\n",
    "- Integrate automated sweeps by wrapping the commands in PowerShell scripts or invoking from CI.\n",
    "\n",
    "With this workflow, any teammate can activate the environment, generate datasets, and train the PE-LiNN model reproducibly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
